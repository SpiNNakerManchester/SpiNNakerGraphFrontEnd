import tensorflow as tf

# TF version 1
#
# in_a = tf.placeholder(dtype=tf.float32, shape=(2))
# in_b = tf.placeholder(dtype=tf.float32, shape=(2))
#
# def forward(x):
#   with tf.variable_scope("matmul", reuse=tf.AUTO_REUSE):
#     W = tf.get_variable("W", initializer=tf.ones(shape=(2,2)),
#                         regularizer=tf.contrib.layers.l2_regularizer(0.04))
#     b = tf.get_variable("b", initializer=tf.zeros(shape=(2)))
#     return W * x + b
#
# out_a = forward(in_a)
# out_b = forward(in_b)
#
# reg_loss = tf.losses.get_regularization_loss(scope="matmul")
#
# with tf.Session() as sess:
#   sess.run(tf.global_variables_initializer())
#   outs = sess.run([out_a, out_b, reg_loss],
#                 feed_dict={in_a: [1, 0], in_b: [0, 1]})




#  TF version 2
W = tf.Variable(tf.ones(shape=(2, 2)), name="W")
b = tf.Variable(tf.zeros(shape=(2)), name="b")


@tf.function
def forward(x):
    return W * x + b


out_a = forward([1, 0])
print(out_a)
out_b = forward([0,1])

regularizer = tf.keras.regularizers.l2(0.04)
reg_loss = regularizer(W)